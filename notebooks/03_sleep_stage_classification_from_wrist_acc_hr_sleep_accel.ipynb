{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c650d906-c163-49f8-bc90-150bf64d40c1",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}\n",
    "\\tableofcontents\n",
    "\\clearpage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d74167-ccb1-42ea-9bf1-dc9e4c23ecee",
   "metadata": {},
   "source": [
    "## 1. Data source: Sleep-Accel (PhysioNet; Apple Watch + PSG)\n",
    "\n",
    "**Dataset:** *Motion and heart rate from a wrist-worn wearable and labeled sleep from polysomnography* (PhysioNet, v1.0.0)\n",
    "\n",
    "- **PhysioNet dataset page (download + description):**   \n",
    "    - https://physionet.org/content/sleep-accel/1.0.0/   \n",
    "- **DOI (v1.0.0):**   \n",
    "    - https://doi.org/10.13026/hmhs-py35   \n",
    "- **Local path (expected):** download + unzip into `./data/sleep_accel/` (the `data/` directory is not committed to git)   \n",
    "    - expected: `heart_rate/`, `motion/`, `labels/`, `steps/`, plus `LICENSE.txt`   \n",
    "- **License (for files):** Open Data Commons Attribution License v1.0 (**ODC-By 1.0**)   \n",
    "\n",
    "**Citations (as requested by PhysioNet):**   \n",
    "- Walch, O. (2019). *Motion and heart rate from a wrist-worn wearable and labeled sleep from polysomnography* (version 1.0.0). PhysioNet. https://doi.org/10.13026/hmhs-py35   \n",
    "- Walch, O., Huang, Y., Forger, D., Goldstein, C. (2019). *Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device*. SLEEP. https://doi.org/10.1093/sleep/zsz180   \n",
    "- Goldberger, A. L., et al. (2000). *PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals*. Circulation.   \n",
    "\n",
    "\n",
    "**Files used(and expected columns)**   \n",
    "\n",
    "We will use the following folders/files from the PhysioNet release:   \n",
    "\n",
    "- **Motion (ACC):** `motion/[subject]_acceleration.txt`  \n",
    "  Columns per line: `t_sec, ax_g, ay_g, az_g`  \n",
    "  where `t_sec` is seconds since PSG start, and accelerations are in **g**.   \n",
    "\n",
    "- **Heart rate (HR):** `heart_rate/[subject]_heartrate.txt`  \n",
    "  Columns per line: `t_sec, hr_bpm`  \n",
    "  where `hr_bpm` is heart rate in **beats per minute**.   \n",
    "\n",
    "- **PSG sleep labels:** `labels/[subject]_labeled_sleep.txt`  \n",
    "  Columns per line: `t_sec, stage` with stage codes:  \n",
    "  `Wake=0, N1=1, N2=2, N3=3, REM=5` (we drop unscored/invalid epochs if present).\n",
    "\n",
    "> Note: The dataset also includes `steps/` files, but we won’t use them in the first version.\n",
    "\n",
    "\n",
    "**Notebook intention**\n",
    "\n",
    "Goal: build a **reproducible sleep-staging pipeline** from **wrist ACC + HR** aligned to **PSG-scored 30-second epochs**, with **leakage-aware, subject-wise evaluation**.\n",
    "\n",
    "What we do:   \n",
    "\n",
    "1. **Define the modeling unit as the PSG epoch (30s)** and build one feature row per epoch.  \n",
    "2. **Align** wrist **ACC** and **HR** to each labeled 30s epoch (aggregate samples falling in `[t, t+30s)`), and attach the PSG stage label at `t`.  \n",
    "3. **Extract simple, readable features** per epoch:   \n",
    "   - ACC: magnitude and axis statistics + activity intensity proxies  \n",
    "   - HR: summary statistics + missingness indicators  \n",
    "4. Add **causal context (history) features** using past-only rolling summaries over recent epochs (e.g., last few minutes) to capture local sleep continuity without using future information.  \n",
    "5. Train and compare a small set of classical models using **subject-wise cross-validation** (GroupKFold) and report robust staging metrics (macro-F1, balanced accuracy, confusion matrices, per-subject performance).  \n",
    "6. Apply a lightweight **temporal stabilization** step (e.g., hysteresis / causal smoothing of probabilities) to reduce one-epoch “blips” and reflect product-realistic output stability.\n",
    "\n",
    "Note on extra “pre-PSG” wearable data:\n",
    "\n",
    "This dataset includes wearable streams that may start **before PSG time zero** (e.g., steps for days prior, HR for hours prior, motion shortly before). For the main staging pipeline we **restrict to the PSG-labeled interval** and only aggregate sensor data within labeled 30s epochs. Pre-PSG data can be used in extensions as **subject-level context** (e.g., prior-days activity summaries computed strictly from `t < 0`), but coverage varies across subjects and adds preprocessing complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414974f-4060-4bf9-8edf-6a85eb42ddf4",
   "metadata": {},
   "source": [
    "## 2. Data loading and check\n",
    "\n",
    "We load per-subject **wrist accelerometer (ACC)**, **heart rate (HR)**, and **PSG sleep labels** from the PhysioNet Sleep-Accel folder structure.\n",
    "\n",
    "Key conventions:\n",
    "- All timestamps are de-identified and expressed as **seconds since PSG start** (`t=0` is the PSG start time).\n",
    "- For the main staging pipeline, we **restrict to the PSG-labeled interval** and only aggregate sensor samples that fall inside each labeled 30s epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b1ad70-2a52-4b5a-aaf3-b6d383f52af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 subjects (from labels/). Example IDs: ['1066528', '1360686', '1449548', '1455390', '1818471']\n",
      "\n",
      "Subject 1066528 loaded:\n",
      "  labels: (952, 2) | t range: [0.0, 28530.0]\n",
      "  hr    : (16617, 2)     | t range: [-355241.7, 34491.2]\n",
      "  acc   : (1281000, 4)    | t range: [-21684.8, 28626.5]\n",
      "\n",
      "Label codes present (counts):\n",
      "stage\n",
      "0    185\n",
      "1     97\n",
      "2    299\n",
      "3     62\n",
      "5    309\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_code</th>\n",
       "      <th>stage_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wake</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N2</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>N3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>REM</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage_code stage_name  count\n",
       "0           0       Wake    185\n",
       "1           1         N1     97\n",
       "2           2         N2    299\n",
       "3           3         N3     62\n",
       "4           5        REM    309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "STAGE_MAP = {\n",
    "    0: \"Wake\",\n",
    "    1: \"N1\",\n",
    "    2: \"N2\",\n",
    "    3: \"N3\",\n",
    "    5: \"REM\",\n",
    "}\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR   = Path(\"../data/sleep_accel\")\n",
    "MOTION_DIR = DATA_DIR / \"motion\"\n",
    "HR_DIR     = DATA_DIR / \"heart_rate\"\n",
    "LABEL_DIR  = DATA_DIR / \"labels\"\n",
    "\n",
    "for d in [DATA_DIR, MOTION_DIR, HR_DIR, LABEL_DIR]:\n",
    "    assert d.exists(), f\"Missing: {d}\"\n",
    "\n",
    "# --- Subject discovery (use labels as the \"source of truth\") ---\n",
    "label_files = sorted(LABEL_DIR.glob(\"*_labeled_sleep.txt\"))\n",
    "assert len(label_files) > 0, f\"No label files found in: {LABEL_DIR}\"\n",
    "\n",
    "SUBJECT_IDS = [re.match(r\"(\\d+)_labeled_sleep\\.txt\", f.name).group(1) for f in label_files]\n",
    "print(f\"Found {len(SUBJECT_IDS)} subjects (from labels/). Example IDs: {SUBJECT_IDS[:5]}\")\n",
    "\n",
    "# --- Loaders ---\n",
    "def load_labels(subject_id: str) -> pd.DataFrame:\n",
    "    \"\"\"Load PSG sleep labels: columns [t_sec, stage].\"\"\"\n",
    "    path = LABEL_DIR / f\"{subject_id}_labeled_sleep.txt\"\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, names=[\"t_sec\", \"stage\"])\n",
    "    df[\"t_sec\"] = df[\"t_sec\"].astype(float)\n",
    "    df[\"stage\"] = df[\"stage\"].astype(int)\n",
    "    df = df.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_hr(subject_id: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Apple Watch HR: columns [t_sec, hr_bpm].\"\"\"\n",
    "    path = HR_DIR / f\"{subject_id}_heartrate.txt\"\n",
    "    df = pd.read_csv(path, sep=\",\", header=None, names=[\"t_sec\", \"hr_bpm\"])\n",
    "    df[\"t_sec\"] = df[\"t_sec\"].astype(float)\n",
    "    df[\"hr_bpm\"] = df[\"hr_bpm\"].astype(float)\n",
    "    df = df.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_acc(subject_id: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Apple Watch accelerometer: columns [t_sec, ax_g, ay_g, az_g].\"\"\"\n",
    "    path = MOTION_DIR / f\"{subject_id}_acceleration.txt\"\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, names=[\"t_sec\", \"ax_g\", \"ay_g\", \"az_g\"])\n",
    "    df[\"t_sec\"] = df[\"t_sec\"].astype(float)\n",
    "    for c in [\"ax_g\", \"ay_g\", \"az_g\"]:\n",
    "        df[c] = df[c].astype(float)\n",
    "    df = df.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# --- Quick sanity check on one subject ---\n",
    "sid = SUBJECT_IDS[0]\n",
    "\n",
    "labels = load_labels(sid)\n",
    "hr     = load_hr(sid)\n",
    "acc    = load_acc(sid)\n",
    "\n",
    "print(f\"\\nSubject {sid} loaded:\")\n",
    "print(f\"  labels: {labels.shape} | t range: [{labels.t_sec.min():.1f}, {labels.t_sec.max():.1f}]\")\n",
    "print(f\"  hr    : {hr.shape}     | t range: [{hr.t_sec.min():.1f}, {hr.t_sec.max():.1f}]\")\n",
    "print(f\"  acc   : {acc.shape}    | t range: [{acc.t_sec.min():.1f}, {acc.t_sec.max():.1f}]\")\n",
    "\n",
    "print(\"\\nLabel codes present (counts):\")\n",
    "print(labels[\"stage\"].value_counts().sort_index())\n",
    "\n",
    "# Show a small peek\n",
    "label_counts = labels[\"stage\"].value_counts().sort_index()\n",
    "display(pd.DataFrame({\n",
    "    \"stage_code\": label_counts.index,\n",
    "    \"stage_name\": [STAGE_MAP.get(int(s), \"OTHER\") for s in label_counts.index],\n",
    "    \"count\": label_counts.values,\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0fee1-7704-470c-9adf-57b5b7507fff",
   "metadata": {},
   "source": [
    "## 3. Epoch alignment (30s) — assign raw samples to PSG epochs\n",
    "\n",
    "We use PSG labels as the **epoch grid** (30s cadence), and assign raw HR and ACC samples to each epoch.\n",
    "\n",
    "Output: one row per epoch with:  \n",
    "- `epoch_id`, `t_start_sec`, `t_end_sec`, `stage_code`  \n",
    "- raw per-epoch sequences: HR (`t_sec`, `hr_bpm`) and ACC (`t_sec`, `ax_g`, `ay_g`, `az_g`)  \n",
    "\n",
    "**Note on sampling rates and interpolation:**  \n",
    "ACC is high-rate, HR is sparse/irregular, and labels are per 30s epoch. We **do not resample or interpolate** signals to a common grid. Instead, we compute **per-epoch summary features** (e.g. counts, mean/std/percentiles, simple trends) directly from the raw samples assigned to each epoch at the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5169bfc0-fa3e-4697-8b2a-459d94a4466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_raw: (952, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_start_sec</th>\n",
       "      <th>stage_code</th>\n",
       "      <th>t_end_sec</th>\n",
       "      <th>epoch_id</th>\n",
       "      <th>hr_t_sec</th>\n",
       "      <th>hr_bpm</th>\n",
       "      <th>acc_t_sec</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.38561010361, 6.38561010361, 6.38561010361, ...</td>\n",
       "      <td>[52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51....</td>\n",
       "      <td>[0.0159480571747, 0.0360059738159, 0.055885076...</td>\n",
       "      <td>[0.4039307, 0.4039154, 0.4049072, 0.4083557, 0...</td>\n",
       "      <td>[0.4490051, 0.4480286, 0.4465485, 0.447525, 0....</td>\n",
       "      <td>[-0.7968597, -0.7953949, -0.7958527, -0.796768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[33.3856399059, 33.3856399059, 33.3856399059, ...</td>\n",
       "      <td>[54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 50.0, 50....</td>\n",
       "      <td>[30.0175080299, 30.0375330448, 30.0574300289, ...</td>\n",
       "      <td>[0.401886, 0.4028931, 0.4028931, 0.4019012, 0....</td>\n",
       "      <td>[0.4564209, 0.4588623, 0.4578857, 0.4573975, 0...</td>\n",
       "      <td>[-0.7906189, -0.7935486, -0.7925568, -0.792083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[64.3856399059, 64.3856399059, 64.3856399059, ...</td>\n",
       "      <td>[50.0, 50.0, 50.0, 52.0, 52.0, 52.0, 53.0, 53....</td>\n",
       "      <td>[60.0183210373, 60.0382120609, 60.058177948, 6...</td>\n",
       "      <td>[0.4048615, 0.4053497, 0.4043732, 0.4043884, 0...</td>\n",
       "      <td>[0.4554291, 0.4554291, 0.4569092, 0.4573822, 0...</td>\n",
       "      <td>[-0.7920227, -0.792511, -0.7925262, -0.7944794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[91.3856399059, 91.3856399059, 91.3856399059, ...</td>\n",
       "      <td>[54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....</td>\n",
       "      <td>[90.0176670551, 90.0374310017, 90.0576291084, ...</td>\n",
       "      <td>[0.4013367, 0.3989563, 0.3989258, 0.4008484, 0...</td>\n",
       "      <td>[0.4633331, 0.4623108, 0.4687195, 0.4623413, 0...</td>\n",
       "      <td>[-0.7853241, -0.7936401, -0.791748, -0.7858124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[122.385639906, 122.385639906, 122.385639906, ...</td>\n",
       "      <td>[56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57....</td>\n",
       "      <td>[120.016488075, 120.036480904, 120.056406975, ...</td>\n",
       "      <td>[0.3984222, 0.4008636, 0.39888, 0.4003754, 0.3...</td>\n",
       "      <td>[0.4662628, 0.4662781, 0.4662781, 0.4672546, 0...</td>\n",
       "      <td>[-0.7907562, -0.7882843, -0.78685, -0.7878113,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_start_sec  stage_code  t_end_sec  epoch_id  \\\n",
       "0          0.0           0       30.0         0   \n",
       "1         30.0           0       60.0         1   \n",
       "2         60.0           0       90.0         2   \n",
       "3         90.0           0      120.0         3   \n",
       "4        120.0           0      150.0         4   \n",
       "\n",
       "                                            hr_t_sec  \\\n",
       "0  [6.38561010361, 6.38561010361, 6.38561010361, ...   \n",
       "1  [33.3856399059, 33.3856399059, 33.3856399059, ...   \n",
       "2  [64.3856399059, 64.3856399059, 64.3856399059, ...   \n",
       "3  [91.3856399059, 91.3856399059, 91.3856399059, ...   \n",
       "4  [122.385639906, 122.385639906, 122.385639906, ...   \n",
       "\n",
       "                                              hr_bpm  \\\n",
       "0  [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51....   \n",
       "1  [54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 50.0, 50....   \n",
       "2  [50.0, 50.0, 50.0, 52.0, 52.0, 52.0, 53.0, 53....   \n",
       "3  [54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....   \n",
       "4  [56.0, 56.0, 56.0, 57.0, 57.0, 57.0, 57.0, 57....   \n",
       "\n",
       "                                           acc_t_sec  \\\n",
       "0  [0.0159480571747, 0.0360059738159, 0.055885076...   \n",
       "1  [30.0175080299, 30.0375330448, 30.0574300289, ...   \n",
       "2  [60.0183210373, 60.0382120609, 60.058177948, 6...   \n",
       "3  [90.0176670551, 90.0374310017, 90.0576291084, ...   \n",
       "4  [120.016488075, 120.036480904, 120.056406975, ...   \n",
       "\n",
       "                                               acc_x  \\\n",
       "0  [0.4039307, 0.4039154, 0.4049072, 0.4083557, 0...   \n",
       "1  [0.401886, 0.4028931, 0.4028931, 0.4019012, 0....   \n",
       "2  [0.4048615, 0.4053497, 0.4043732, 0.4043884, 0...   \n",
       "3  [0.4013367, 0.3989563, 0.3989258, 0.4008484, 0...   \n",
       "4  [0.3984222, 0.4008636, 0.39888, 0.4003754, 0.3...   \n",
       "\n",
       "                                               acc_y  \\\n",
       "0  [0.4490051, 0.4480286, 0.4465485, 0.447525, 0....   \n",
       "1  [0.4564209, 0.4588623, 0.4578857, 0.4573975, 0...   \n",
       "2  [0.4554291, 0.4554291, 0.4569092, 0.4573822, 0...   \n",
       "3  [0.4633331, 0.4623108, 0.4687195, 0.4623413, 0...   \n",
       "4  [0.4662628, 0.4662781, 0.4662781, 0.4672546, 0...   \n",
       "\n",
       "                                               acc_z  \n",
       "0  [-0.7968597, -0.7953949, -0.7958527, -0.796768...  \n",
       "1  [-0.7906189, -0.7935486, -0.7925568, -0.792083...  \n",
       "2  [-0.7920227, -0.792511, -0.7925262, -0.7944794...  \n",
       "3  [-0.7853241, -0.7936401, -0.791748, -0.7858124...  \n",
       "4  [-0.7907562, -0.7882843, -0.78685, -0.7878113,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCH_SEC = 30\n",
    "\n",
    "# --- sort for safety (merge_asof requires sorted keys) ---\n",
    "labels_s = labels.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "hr_s     = hr.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "acc_s    = acc.sort_values(\"t_sec\", kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "# --- epoch grid from labels (PSG epochs) ---\n",
    "epochs = (\n",
    "    labels_s.loc[labels_s[\"stage\"].isin(STAGE_MAP.keys()), [\"t_sec\", \"stage\"]]\n",
    "    .rename(columns={\"t_sec\": \"t_start_sec\", \"stage\": \"stage_code\"})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "epochs[\"t_end_sec\"] = epochs[\"t_start_sec\"] + EPOCH_SEC\n",
    "epochs[\"epoch_id\"] = epochs.index.astype(int)\n",
    "\n",
    "# --- HR: assign each sample to the latest epoch start (backward), then keep only within [start, end) ---\n",
    "hr_join = pd.merge_asof(\n",
    "    hr_s, epochs[[\"t_start_sec\", \"t_end_sec\", \"epoch_id\"]],\n",
    "    left_on=\"t_sec\", right_on=\"t_start_sec\",\n",
    "    direction=\"backward\",\n",
    ")\n",
    "# Keep only samples that truly fall inside the assigned epoch window [t_start, t_end)\n",
    "hr_join = hr_join[hr_join[\"t_sec\"] < hr_join[\"t_end_sec\"]]\n",
    "\n",
    "hr_raw = (\n",
    "    hr_join.groupby(\"epoch_id\", sort=True)[[\"t_sec\", \"hr_bpm\"]]\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"hr_t_sec\": g[\"t_sec\"].to_numpy(),\n",
    "        \"hr_bpm\":  g[\"hr_bpm\"].to_numpy(),\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# --- ACC: same assignment ---\n",
    "acc_join = pd.merge_asof(\n",
    "    acc_s, epochs[[\"t_start_sec\", \"t_end_sec\", \"epoch_id\"]],\n",
    "    left_on=\"t_sec\", right_on=\"t_start_sec\",\n",
    "    direction=\"backward\",\n",
    ")\n",
    "acc_join = acc_join[acc_join[\"t_sec\"] < acc_join[\"t_end_sec\"]]\n",
    "\n",
    "acc_raw = (\n",
    "    acc_join.groupby(\"epoch_id\", sort=True)[[\"t_sec\", \"ax_g\", \"ay_g\", \"az_g\"]]\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"acc_t_sec\": g[\"t_sec\"].to_numpy(),\n",
    "        \"acc_x\":     g[\"ax_g\"].to_numpy(),\n",
    "        \"acc_y\":     g[\"ay_g\"].to_numpy(),\n",
    "        \"acc_z\":     g[\"az_g\"].to_numpy(),\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# --- epoch table with raw sequences (no features yet) ---\n",
    "epoch_raw = (\n",
    "    epochs.merge(hr_raw, on=\"epoch_id\", how=\"left\")\n",
    "          .merge(acc_raw, on=\"epoch_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"epoch_raw:\", epoch_raw.shape)\n",
    "display(epoch_raw.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c78bc-5a25-4aca-baa0-4ff03f6e928f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d64fe-c50d-461b-af7f-618428ab0321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Chouaib (github.com/ChouaibB)"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "title": "Sleep Stage Classification from Wrist ACC + Heart Rate (PhysioNet Sleep-Accel / Apple Watch)"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
